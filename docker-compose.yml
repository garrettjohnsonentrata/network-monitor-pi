version: "3.8"

services:
  # =============================================================================
  # PROMETHEUS - Time Series Database & Metrics Collection
  # =============================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=512MB'
      - '--web.enable-lifecycle'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/blackbox.yml:/etc/prometheus/blackbox.yml:ro
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - ./prometheus/targets:/etc/prometheus/targets:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 300M
        reservations:
          memory: 150M
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # GRAFANA - Visualization & Dashboards
  # =============================================================================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_INSTALL_PLUGINS=
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3000:3000"
    networks:
      - monitoring
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 200M
        reservations:
          memory: 100M
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # BLACKBOX EXPORTER - ICMP Ping & Probe Monitoring
  # =============================================================================
  blackbox:
    image: prom/blackbox-exporter:v0.24.0
    container_name: blackbox
    restart: unless-stopped
    command:
      - '--config.file=/etc/blackbox/blackbox.yml'
    volumes:
      - ./prometheus/blackbox.yml:/etc/blackbox/blackbox.yml:ro
    ports:
      - "9115:9115"
    networks:
      - monitoring
    cap_add:
      - NET_RAW
    deploy:
      resources:
        limits:
          memory: 50M
        reservations:
          memory: 25M
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9115/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # NODE EXPORTER - Raspberry Pi System Metrics
  # =============================================================================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 50M
        reservations:
          memory: 25M
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9100/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # SPEEDTEST EXPORTER - Bandwidth Monitoring (Hourly)
  # =============================================================================
  speedtest:
    image: miguelndecarvalho/speedtest-exporter:v3.5.4
    container_name: speedtest
    restart: unless-stopped
    ports:
      - "9798:9798"
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 50M

  # =============================================================================
  # ALERTMANAGER - Notifications & Alert Routing
  # =============================================================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager
    restart: unless-stopped
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    ports:
      - "9093:9093"
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 30M
        reservations:
          memory: 15M
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  # =============================================================================
  # DISCORD RELAY - Alertmanager Webhook -> Discord Webhook
  # =============================================================================
  discord-relay:
    image: python:3.12-alpine
    container_name: discord-relay
    restart: unless-stopped
    command: ["python", "/app/discord_relay.py"]
    env_file:
      - ./.env
    volumes:
      - ./scripts/discord_relay.py:/app/discord_relay.py:ro
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 40M
        reservations:
          memory: 20M

  # =============================================================================
  # UPTIME KUMA - Lightweight Uptime Monitoring
  # =============================================================================
  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    restart: unless-stopped
    volumes:
      - uptime-kuma-data:/app/data
    ports:
      - "3001:3001"
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 80M
        reservations:
          memory: 40M

  # =============================================================================
  # VNSTAT - Bandwidth Usage Tracking (Host Network Required)
  # =============================================================================
  vnstat:
    image: vergoh/vnstat:latest
    container_name: vnstat
    restart: unless-stopped
    network_mode: host
    volumes:
      - vnstat-data:/var/lib/vnstat
    environment:
      - INTERFACE=eth0
    deploy:
      resources:
        limits:
          memory: 15M
        reservations:
          memory: 8M

  # =============================================================================
  # VNSTAT EXPORTER - Prometheus Metrics for Bandwidth Usage
  # =============================================================================
  vnstat-exporter:
    image: jbrunicardi/vnstat-exporter:latest
    container_name: vnstat-exporter
    restart: unless-stopped
    volumes:
      - vnstat-data:/var/lib/vnstat:ro
    ports:
      - "9176:9176"
    networks:
      - monitoring
    depends_on:
      - vnstat
    deploy:
      resources:
        limits:
          memory: 15M
        reservations:
          memory: 8M

  # =============================================================================
  # GATEWAY FINDER - Auto-Discovery Sidecar
  # =============================================================================
  gateway-finder:
    image: alpine:3.19
    container_name: gateway-finder
    restart: unless-stopped
    network_mode: host
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        apk add --no-cache iproute2 jq
        echo "* * * * * /scripts/gateway_finder.sh" | crontab -
        # Run once immediately on startup
        /scripts/gateway_finder.sh
        # Start cron in foreground
        crond -f -l 2
    volumes:
      - ./scripts/gateway_finder.sh:/scripts/gateway_finder.sh:ro
      - ./prometheus/targets:/targets
    deploy:
      resources:
        limits:
          memory: 32M
        reservations:
          memory: 16M

networks:
  monitoring:
    driver: bridge

volumes:
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  uptime-kuma-data:
    driver: local
  vnstat-data:
    driver: local